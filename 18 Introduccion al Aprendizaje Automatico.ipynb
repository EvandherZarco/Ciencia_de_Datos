{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción al Aprendizaje Automático\n",
    "\n",
    "### Definición de aprendizaje automático\n",
    "El aprendizaje automático es una rama de la inteligencia artificial que se enfoca en el desarrollo de algoritmos y técnicas que permiten a las computadoras aprender y hacer predicciones o tomar decisiones basadas en datos. A diferencia de los sistemas tradicionales que siguen reglas predefinidas, los sistemas de aprendizaje automático mejoran su rendimiento a través de la experiencia.\n",
    "\n",
    "### Importancia y aplicaciones\n",
    "El aprendizaje automático tiene una amplia gama de aplicaciones en diversas áreas, incluyendo:\n",
    "- Reconocimiento de voz\n",
    "- Visión por computadora\n",
    "- Sistemas de recomendación\n",
    "- Diagnóstico médico\n",
    "- Finanzas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings,\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cargar el conjunto de datos de calidad del vino\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "data = pd.read_csv(url, delimiter=';')\n",
    "\n",
    "# Mostrar las primeras filas del conjunto de datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descripción del conjunto de datos\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la distribución de la calidad del vino\n",
    "sns.countplot(x='quality', data=data)\n",
    "plt.title('Distribución de la Calidad del Vino')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las relaciones entre características\n",
    "sns.pairplot(data, hue='quality')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tipos de Aprendizaje Automático\n",
    "\n",
    "### Aprendizaje Supervisado\n",
    "En el aprendizaje supervisado, el modelo se entrena utilizando un conjunto de datos etiquetados. Esto significa que cada muestra de datos de entrenamiento incluye las entradas y las salidas esperadas. El objetivo es aprender una función que mapea las entradas a las salidas. Los algoritmos de aprendizaje supervisado se dividen en dos categorías principales:\n",
    "- **Regresión**: Utilizado para predecir valores continuos. Ejemplos comunes incluyen:\n",
    "  - Regresión Lineal\n",
    "  - Regresión Polinómica\n",
    "  - Regresión Ridge\n",
    "  - Regresión Lasso\n",
    "- **Clasificación**: Utilizado para predecir categorías o clases. Ejemplos comunes incluyen:\n",
    "  - Regresión Logística\n",
    "  - Máquinas de Soporte Vectorial (SVM)\n",
    "  - Árboles de Decisión\n",
    "  - Bosques Aleatorios\n",
    "  - k-Vecinos más Cercanos (k-NN)\n",
    "  - Redes Neuronales\n",
    "\n",
    "### Aprendizaje No Supervisado\n",
    "En el aprendizaje no supervisado, el modelo se entrena utilizando un conjunto de datos sin etiquetar. El objetivo es encontrar patrones o estructuras ocultas en los datos. Los algoritmos de aprendizaje no supervisado se utilizan principalmente para:\n",
    "- **Clustering**: Agrupar datos similares. Ejemplos comunes incluyen:\n",
    "  - k-Means\n",
    "  - Clustering Jerárquico\n",
    "  - DBSCAN\n",
    "- **Reducción de Dimensionalidad**: Reducir el número de características en los datos mientras se preserva la mayor cantidad de información posible. Ejemplos comunes incluyen:\n",
    "  - Análisis de Componentes Principales (PCA)\n",
    "  - Análisis Discriminante Lineal (LDA)\n",
    "  - t-SNE\n",
    "\n",
    "### Aprendizaje Semi-Supervisado y por Refuerzo\n",
    "- **Aprendizaje Semi-Supervisado**: Combina una pequeña cantidad de datos etiquetados con una gran cantidad de datos sin etiquetar. Este enfoque es útil cuando etiquetar datos es costoso o requiere mucho tiempo. Los algoritmos semi-supervisados pueden mejorar la precisión del modelo aprovechando la gran cantidad de datos no etiquetados.\n",
    "- **Aprendizaje por Refuerzo**: El modelo aprende a tomar decisiones secuenciales optimizando una recompensa acumulada. Se utiliza principalmente en problemas donde una acción conduce a un estado y el agente debe aprender a maximizar las recompensas a lo largo del tiempo. Ejemplos comunes incluyen:\n",
    "  - Algoritmos Q-Learning\n",
    "  - Algoritmos de Política (Policy Gradient)\n",
    "  - Redes Neuronales Profundas de Aprendizaje por Refuerzo (Deep Reinforcement Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Aplicar KMeans para clustering\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(data.iloc[:, :-1])\n",
    "data['cluster'] = kmeans.labels_\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducir dimensiones para visualización\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform(data.iloc[:, :-2])\n",
    "\n",
    "data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los clusters\n",
    "plt.scatter(data_pca[:, 0], data_pca[:, 1], c=data['cluster'], cmap='viridis')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('Clustering KMeans en el conjunto de datos iris')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conceptos Básicos\n",
    "\n",
    "### Modelo\n",
    "Un modelo en aprendizaje automático es una representación matemática de un proceso basado en datos que se utiliza para hacer predicciones o tomar decisiones. Los modelos pueden ser de diversos tipos, dependiendo del problema a resolver, como regresión, clasificación, clustering, entre otros.\n",
    "\n",
    "### Algoritmo\n",
    "Un algoritmo es un conjunto de reglas o instrucciones que un modelo sigue para aprender a partir de los datos. Los algoritmos determinan cómo se ajustan los parámetros del modelo durante el proceso de entrenamiento. Ejemplos de algoritmos incluyen:\n",
    "\n",
    "- **Regresión Lineal**: Ajusta una línea recta a los datos para predecir valores continuos.\n",
    "- **Máquinas de Soporte Vectorial (SVM)**: Encuentra el hiperplano que mejor separa las clases en el espacio de características.\n",
    "- **Redes Neuronales**: Modelos inspirados en el cerebro humano que aprenden a través de capas de neuronas artificiales.\n",
    "- **Árboles de Decisión**: Modelo basado en reglas de decisión en forma de árbol para clasificar o predecir valores.\n",
    "\n",
    "### Entrenamiento y Predicción\n",
    "- **Entrenamiento**: Es el proceso de ajustar el modelo a los datos de entrenamiento. Durante este proceso, el modelo aprende las relaciones entre las características de entrada y las salidas esperadas. El objetivo es minimizar una función de pérdida que mide el error entre las predicciones del modelo y los valores reales.\n",
    "  \n",
    "- **Predicción**: Es el uso del modelo entrenado para hacer inferencias sobre nuevos datos no vistos. En esta fase, el modelo aplica el conocimiento adquirido durante el entrenamiento para generar predicciones. Para la regresión, esto podría ser un valor continuo, mientras que para la clasificación, esto sería una clase o categoría.\n",
    "\n",
    "### Conjunto de Datos y Características\n",
    "- **Conjunto de Datos**: Es una colección de datos que se utilizan para entrenar y evaluar el modelo. Puede estar compuesto por datos estructurados (como tablas con filas y columnas) o no estructurados (como texto, imágenes y audio). Es fundamental tener un conjunto de datos representativo para asegurar que el modelo generalice bien a nuevos datos.\n",
    "\n",
    "- **Características (Features)**: Son las variables de entrada que se utilizan para hacer predicciones. Las características pueden ser numéricas (por ejemplo, altura, peso), categóricas (por ejemplo, género, país) o derivadas (por ejemplo, interacciones entre características). La selección y transformación adecuadas de las características son cruciales para el desempeño del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Proceso de Aprendizaje Automático\n",
    "\n",
    "### Carga y Limpieza de Datos\n",
    "El primer paso en el proceso de aprendizaje automático es cargar los datos y limpiarlos para asegurarse de que estén en un formato adecuado para el análisis. Esto puede incluir la eliminación de valores nulos, la corrección de errores, y la transformación de las características para que sean más adecuadas para el modelo.\n",
    "\n",
    "### División del Conjunto de Datos en Entrenamiento y Prueba\n",
    "Dividimos el conjunto de datos en dos partes: uno para entrenar el modelo (conjunto de entrenamiento) y otro para evaluar su desempeño (conjunto de prueba). Esto nos ayuda a verificar que el modelo generaliza bien y no solo memoriza los datos de entrenamiento.\n",
    "\n",
    "### Selección y Entrenamiento del Modelo\n",
    "Elegimos un modelo adecuado para el problema que estamos resolviendo y lo entrenamos utilizando los datos de entrenamiento. Durante el entrenamiento, el modelo aprende las relaciones entre las características de entrada y las salidas esperadas.\n",
    "\n",
    "### Evaluación del Modelo\n",
    "Evaluamos el desempeño del modelo utilizando los datos de prueba y varias métricas de evaluación, como la exactitud, precisión, recall, F1 Score, entre otras. Esto nos permite entender cómo de bien está funcionando el modelo en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "# Dividir el conjunto de datos en características (X) y etiquetas (y)\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# ---- Clasificación ----\n",
    "# Crear y entrenar un modelo de regresión logística multinomial\n",
    "log_model = LogisticRegression(max_iter=200,\n",
    "                               multi_class='multinomial', solver='lbfgs')\n",
    "log_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones de clasificación\n",
    "y_pred_class = log_model.predict(X_test)\n",
    "\n",
    "# ---- Regresión ----\n",
    "# Crear y entrenar un modelo de regresión lineal\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones de regresión\n",
    "y_pred_reg = reg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las predicciones y una muestra de los valores reales para comparación\n",
    "print(\"Predicciones de clasificación (muestra):\", y_pred_class[:10])\n",
    "print(\"Valores reales de clasificación (muestra):\", y_test[:10].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicciones de regresión (muestra):\", y_pred_reg[:10])\n",
    "print(\"Valores reales de regresión (muestra):\", y_test[:10].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Métricas de Evaluación\n",
    "\n",
    "Las métricas de evaluación son fundamentales para medir el desempeño de un modelo de aprendizaje automático. Las métricas presentadas aquí son específicas para problemas de clasificación. Para problemas de regresión, se utilizan métricas diferentes como el error cuadrático medio (MSE) o el coeficiente de determinación ($R^2$).\n",
    "\n",
    "### Variables Comunes en las Fórmulas\n",
    "- **Verdaderos Positivos (TP)**: Número de instancias correctamente predichas como positivas.\n",
    "- **Falsos Positivos (FP)**: Número de instancias incorrectamente predichas como positivas.\n",
    "- **Verdaderos Negativos (TN)**: Número de instancias correctamente predichas como negativas.\n",
    "- **Falsos Negativos (FN)**: Número de instancias incorrectamente predichas como negativas.\n",
    "\n",
    "### Precisión\n",
    "La precisión es la proporción de verdaderos positivos entre los positivos predichos. Es útil cuando el costo de los falsos positivos es alto.\n",
    "\n",
    "$$ \\text{Precisión} = \\frac{\\text{Verdaderos Positivos (TP)}}{\\text{Verdaderos Positivos (TP)} + \\text{Falsos Positivos (FP)}} $$\n",
    "\n",
    "### Exactitud (Accuracy)\n",
    "La exactitud es la proporción de predicciones correctas sobre el total de predicciones. Es una métrica global que considera tanto positivos como negativos.\n",
    "\n",
    "$$ \\text{Exactitud} = \\frac{\\text{Verdaderos Positivos (TP)} + \\text{Verdaderos Negativos (TN)}}{\\text{Total de Predicciones}} $$\n",
    "\n",
    "### Sensibilidad (Recall)\n",
    "La sensibilidad, también conocida como recall, es la proporción de verdaderos positivos entre los positivos reales. Es útil cuando el costo de los falsos negativos es alto.\n",
    "\n",
    "$$ \\text{Sensibilidad} = \\frac{\\text{Verdaderos Positivos (TP)}}{\\text{Verdaderos Positivos (TP)} + \\text{Falsos Negativos (FN)}} $$\n",
    "\n",
    "### Especificidad\n",
    "La especificidad es la proporción de verdaderos negativos entre los negativos reales. Es útil cuando el costo de los falsos positivos es alto.\n",
    "\n",
    "$$ \\text{Especificidad} = \\frac{\\text{Verdaderos Negativos (TN)}}{\\text{Verdaderos Negativos (TN)} + \\text{Falsos Positivos (FP)}} $$\n",
    "\n",
    "### F1 Score\n",
    "El F1 Score es la media armónica de la precisión y la sensibilidad. Es una métrica útil cuando se busca un equilibrio entre precisión y sensibilidad.\n",
    "\n",
    "$$ \\text{F1 Score} = 2 \\times \\frac{\\text{Precisión} \\times \\text{Sensibilidad}}{\\text{Precisión} + \\text{Sensibilidad}} $$\n",
    "\n",
    "### Métricas para Regresión\n",
    "En problemas de regresión, utilizamos diferentes métricas como:\n",
    "\n",
    "- **Error Cuadrático Medio (MSE)**: Promedio de los cuadrados de los errores o desviaciones, es decir, la diferencia entre el valor predicho y el valor real.\n",
    "\n",
    "  $$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $$\n",
    "\n",
    "- **Coeficiente de Determinación ($R^2$)**: Medida de la proporción de la variación total del resultado que es explicada por el modelo.\n",
    "\n",
    "  $$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2} $$\n",
    "\n",
    "Donde:\n",
    "- $y_i$ es el valor real.\n",
    "- $\\hat{y}_i$ es el valor predicho.\n",
    "- $\\bar{y}$ es el valor medio de $y$.\n",
    "- $n$ es el número de observaciones.\n",
    "\n",
    "### Interpretación del `classification_report`\n",
    "El `classification_report` proporciona una evaluación detallada de las métricas de clasificación para cada clase en el conjunto de datos. Las métricas incluyen:\n",
    "\n",
    "- **Precision**: La proporción de verdaderos positivos sobre todos los casos predichos como positivos.\n",
    "- **Recall (Sensibilidad)**: La proporción de verdaderos positivos sobre todos los casos realmente positivos.\n",
    "- **F1-Score**: La media armónica de precisión y recall, útil cuando se busca un equilibrio entre ambos.\n",
    "- **Support**: El número de ocurrencias de cada clase en el conjunto de datos real.\n",
    "\n",
    "El `classification_report` también proporciona las métricas agregadas:\n",
    "- **Accuracy (Exactitud)**: Proporción de predicciones correctas.\n",
    "- **Macro avg**: Promedio no ponderado de las métricas para cada clase.\n",
    "- **Weighted avg**: Promedio ponderado de las métricas para cada clase, teniendo en cuenta el support de cada clase.\n",
    "\n",
    "### Interpretación de la Matriz de Confusión\n",
    "La matriz de confusión es una herramienta para visualizar el desempeño del modelo de clasificación. Cada fila de la matriz representa las instancias de una clase real, mientras que cada columna representa las instancias de una clase predicha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluar el modelo de clasificación\n",
    "\n",
    "# Obtener las métricas de evaluación\n",
    "print(\"Evaluación del Modelo de Clasificación:\\n\")\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_class), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicho')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo de regresión\n",
    "\n",
    "# Calcular el Error Cuadrático Medio (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred_reg)\n",
    "print(f\"Error Cuadrático Medio (MSE): {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular el Coeficiente de Determinación (R²)\n",
    "r2 = r2_score(y_test, y_pred_reg)\n",
    "print(f\"Coeficiente de Determinación (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los resultados de la regresión\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(y_test, y_pred_reg, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Valores Reales')\n",
    "plt.ylabel('Valores Predichos')\n",
    "plt.title('Regresión: Valores Reales vs. Valores Predichos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Regularización\n",
    "\n",
    "### Sobreajuste (Overfitting)\n",
    "El sobreajuste ocurre cuando un modelo se ajusta demasiado bien a los datos de entrenamiento, capturando el ruido y las fluctuaciones, lo que resulta en un mal desempeño en los datos de prueba. Esto sucede cuando el modelo es demasiado complejo y tiene demasiados parámetros en relación con la cantidad de datos de entrenamiento.\n",
    "\n",
    "### Subajuste (Underfitting)\n",
    "El subajuste ocurre cuando un modelo es demasiado simple para capturar las relaciones subyacentes en los datos. Esto sucede cuando el modelo no tiene suficiente capacidad para aprender de los datos de entrenamiento, resultando en un desempeño deficiente tanto en los datos de entrenamiento como en los de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Validación Cruzada\n",
    "\n",
    "### Concepto y Importancia\n",
    "La validación cruzada es una técnica para evaluar la capacidad de generalización de un modelo dividiendo los datos en múltiples subconjuntos y entrenando/evaluando el modelo múltiples veces. Esto ayuda a garantizar que el modelo no solo funcione bien en un subconjunto específico de datos, sino que también generalice bien a datos no vistos.\n",
    "\n",
    "### Métodos de Validación Cruzada\n",
    "\n",
    "#### K-Fold Cross-Validation\n",
    "En K-Fold Cross-Validation, los datos se dividen en K subconjuntos (o \"folds\"). El modelo se entrena en K-1 subconjuntos y se evalúa en el subconjunto restante. Este proceso se repite K veces, utilizando un subconjunto diferente para la evaluación en cada iteración. La puntuación final es el promedio de las puntuaciones de las K iteraciones.\n",
    "\n",
    "#### Leave-One-Out Cross-Validation (LOOCV)\n",
    "En Leave-One-Out Cross-Validation (LOOCV), cada muestra de datos se utiliza como un subconjunto de prueba, mientras que las muestras restantes se utilizan como el conjunto de entrenamiento. Este proceso se repite tantas veces como muestras haya en el conjunto de datos. Aunque LOOCV puede proporcionar una evaluación detallada del modelo, puede ser computacionalmente costoso para grandes conjuntos de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Crear el modelo de regresión logística multinomial\n",
    "model = LogisticRegression(max_iter=200, multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Obtener predicciones utilizando validación cruzada\n",
    "y_pred_cv = cross_val_predict(model, X, y, cv=50)\n",
    "\n",
    "# Generar el reporte de clasificación\n",
    "print(\"Reporte de Clasificación utilizando Validación Cruzada:\\n\")\n",
    "print(classification_report(y, y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar la matriz de confusión\n",
    "print(\"Matriz de Confusión utilizando Validación Cruzada:\")\n",
    "print(confusion_matrix(y, y_pred_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(confusion_matrix(y, y_pred_cv), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel('Predicho')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión (Validación Cruzada)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "En esta libreta, hemos explorado el proceso completo de aprendizaje automático utilizando el conjunto de datos de calidad del vino. A lo largo de las secciones, hemos cubierto los siguientes puntos clave:\n",
    "\n",
    "1. **Carga y Exploración de Datos**: Cargamos el conjunto de datos de calidad del vino y exploramos su estructura y distribución. Visualizamos las relaciones entre las características y la distribución de la calidad del vino.\n",
    "\n",
    "2. **División del Conjunto de Datos**: Dividimos el conjunto de datos en conjuntos de entrenamiento y prueba para evaluar adecuadamente el desempeño de los modelos.\n",
    "\n",
    "3. **Selección y Entrenamiento del Modelo**: Entrenamos un modelo de regresión logística multinomial para la clasificación y modelos de regresión Ridge y Lasso para ilustrar la regularización.\n",
    "\n",
    "4. **Evaluación del Modelo**: Evaluamos los modelos utilizando métricas adecuadas como la precisión, sensibilidad, F1 Score, error cuadrático medio (MSE) y el coeficiente de determinación (R²). Generamos y visualizamos la matriz de confusión para entender mejor el desempeño del modelo de clasificación.\n",
    "\n",
    "5. **Validación Cruzada**: Implementamos la validación cruzada para obtener una evaluación más robusta del modelo. Utilizamos `cross_val_predict` para generar predicciones mediante validación cruzada y evaluamos las métricas de clasificación correspondientes.\n",
    "\n",
    "### Reflexión Final\n",
    "\n",
    "El proceso de aprendizaje automático involucra múltiples etapas, desde la carga y limpieza de datos hasta la evaluación y validación del modelo. Cada etapa es crucial para asegurar que el modelo no solo aprenda de los datos de entrenamiento, sino que también generalice bien a nuevos datos. Las técnicas de regularización y validación cruzada son herramientas esenciales para mejorar y evaluar el desempeño del modelo.\n",
    "\n",
    "Esta libreta proporciona una guía práctica para implementar estos conceptos utilizando Python y bibliotecas de aprendizaje automático como scikit-learn. Esperamos que esta guía haya sido útil y que puedas aplicar estos conceptos en tus propios proyectos de aprendizaje automático."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
